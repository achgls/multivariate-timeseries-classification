{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rc('font', size=16) \nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\nimport warnings\nimport logging\n\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-15T09:57:05.317474Z","iopub.execute_input":"2022-12-15T09:57:05.318204Z","iopub.status.idle":"2022-12-15T09:57:16.472126Z","shell.execute_reply.started":"2022-12-15T09:57:05.318072Z","shell.execute_reply":"2022-12-15T09:57:16.471130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:57:22.642398Z","iopub.execute_input":"2022-12-15T09:57:22.642755Z","iopub.status.idle":"2022-12-15T09:57:22.648191Z","shell.execute_reply.started":"2022-12-15T09:57:22.642724Z","shell.execute_reply":"2022-12-15T09:57:22.647289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_val= np.load('/kaggle/input/time-series/x_train.npy')\ny_train_val=np.load('/kaggle/input/time-series/y_train.npy')","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:57:24.718698Z","iopub.execute_input":"2022-12-15T09:57:24.719061Z","iopub.status.idle":"2022-12-15T09:57:24.825128Z","shell.execute_reply.started":"2022-12-15T09:57:24.719029Z","shell.execute_reply":"2022-12-15T09:57:24.824196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X_train shape\",x_train_val.shape)\nprint(\"Y_train shape\",y_train_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:57:27.323769Z","iopub.execute_input":"2022-12-15T09:57:27.324696Z","iopub.status.idle":"2022-12-15T09:57:27.331218Z","shell.execute_reply.started":"2022-12-15T09:57:27.324642Z","shell.execute_reply":"2022-12-15T09:57:27.329772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels={0: \"Wish\",\n1: \"Another\",\n2: \"Comfortably\",\n3: \"Money\",\n4: \"Breathe\",\n5: \"Time\",\n6: \"Brain\",\n7: \"Echoes\",\n8: \"Wearing\",\n9: \"Sorrow\",\n10: \"Hey\",\n11: \"Shine\"}","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:58:25.003986Z","iopub.execute_input":"2022-12-15T09:58:25.004381Z","iopub.status.idle":"2022-12-15T09:58:25.010329Z","shell.execute_reply.started":"2022-12-15T09:58:25.004348Z","shell.execute_reply":"2022-12-15T09:58:25.008864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# UNDERSTANDING THE DATA : VISUALIZE\n\n# At first it appears like: the data is represented on 36 pts time series, and for \n# each point of time there is a value for 6 different features; it is then 36 pts \n# time series of 6 different features\n\ndef plot_example(random_index, x,y ):\n    example=x[random_index]\n    example_label=y[random_index]\n\n    n_points=example.shape[0] # 36\n    n_features=example.shape[1] # 6\n\n    counter=0\n    fig, axs= plt.subplots(2, 3, figsize=(20,10))\n    fig.suptitle('Category : '+labels[example_label])\n    for i in range(n_features):\n        row= counter//3\n        col= counter%3\n        example_on_ith_feature=example[:,i]\n        axs[row,col].set_title('Feature Â° '+str(i+1))\n        axs[row,col].plot(example_on_ith_feature)\n        counter=counter+1\n\n\n\n\nrandom_index=np.random.randint(0,2428) \nplot_example(random_index,x_train_val,y_train_val)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:58:26.963399Z","iopub.execute_input":"2022-12-15T09:58:26.963771Z","iopub.status.idle":"2022-12-15T09:58:27.671208Z","shell.execute_reply.started":"2022-12-15T09:58:26.963742Z","shell.execute_reply":"2022-12-15T09:58:27.670267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CLASS REPARTITIONS\n\nclass_repartitions={\"Wish\":0,\n\"Another\":0,\n\"Comfortably\":0,\n\"Money\":0,\n\"Breathe\":0,\n\"Time\":0,\n\"Brain\":0,\n\"Echoes\":0,\n\"Wearing\":0,\n\"Sorrow\":0,\n\"Hey\":0,\n\"Shine\":0}\n\nfor y in y_train_val:\n    label=labels[y]\n    class_repartitions[label]=class_repartitions[label]+1\n    \nS=0\nfor key in class_repartitions:\n    S=S+class_repartitions[key]\n\n\nprint(\"TOTAL : \",S)\nplt.figure(figsize=(20,20))\nplt.bar(class_repartitions.keys(), class_repartitions.values(), color='g')\n\n\n# ===> UNBALANCED DATASET","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:58:30.278737Z","iopub.execute_input":"2022-12-15T09:58:30.279098Z","iopub.status.idle":"2022-12-15T09:58:30.621308Z","shell.execute_reply.started":"2022-12-15T09:58:30.279067Z","shell.execute_reply":"2022-12-15T09:58:30.620259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_total=x_train_val.shape[0]\nn_classes=12\n\n\nclass_loss_weights = {\n    class_number: (1 / class_repartitions[labels[class_number]]) * (n_total / 12) for class_number in range(12)\n}\n\nclass_loss_weights","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:58:33.916131Z","iopub.execute_input":"2022-12-15T09:58:33.916862Z","iopub.status.idle":"2022-12-15T09:58:33.924812Z","shell.execute_reply.started":"2022-12-15T09:58:33.916822Z","shell.execute_reply":"2022-12-15T09:58:33.923720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WORKING THE DATA IN AMOUNT","metadata":{"execution":{"iopub.status.busy":"2022-12-11T16:35:41.102774Z","iopub.execute_input":"2022-12-11T16:35:41.103382Z","iopub.status.idle":"2022-12-11T16:35:41.114523Z","shell.execute_reply.started":"2022-12-11T16:35:41.103324Z","shell.execute_reply":"2022-12-11T16:35:41.112906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PREPROCESSING","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Studiying each feature/variable separately (statistics, distribution, boxplots ...)\n\nx_train_val_flattened =[]\ny_train_val_flattened=[]\n\nfor i in range(n_total):\n    for k in range(36):\n        x_train_val_flattened.append([])\n        y_train_val_flattened.append(y_train_val[i])\n        for f in range(6):\n            x_train_val_flattened[len(x_train_val_flattened)-1].append(x_train_val[i,k,f])\n\nx_train_val_flattened=np.array(x_train_val_flattened)           \n\n\ndf=pd.DataFrame(x_train_val_flattened)\ndf[\"class\"] = y_train_val_flattened\ndf[\"class_name\"] = [ labels[y] for y in y_train_val_flattened]","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:58:36.783039Z","iopub.execute_input":"2022-12-15T09:58:36.783436Z","iopub.status.idle":"2022-12-15T09:58:37.787040Z","shell.execute_reply.started":"2022-12-15T09:58:36.783404Z","shell.execute_reply":"2022-12-15T09:58:37.785946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:58:39.930521Z","iopub.execute_input":"2022-12-15T09:58:39.930988Z","iopub.status.idle":"2022-12-15T09:58:39.984876Z","shell.execute_reply.started":"2022-12-15T09:58:39.930948Z","shell.execute_reply":"2022-12-15T09:58:39.983822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some info on the dataset\n\ndf[[0,1,2,3,4,5]].describe()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:58:42.495186Z","iopub.execute_input":"2022-12-15T09:58:42.495895Z","iopub.status.idle":"2022-12-15T09:58:42.573747Z","shell.execute_reply.started":"2022-12-15T09:58:42.495853Z","shell.execute_reply":"2022-12-15T09:58:42.572656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taking outliers into account for scaling : ROBUST SCALER !!!!","metadata":{"execution":{"iopub.status.busy":"2022-12-14T15:44:15.366693Z","iopub.execute_input":"2022-12-14T15:44:15.367058Z","iopub.status.idle":"2022-12-14T15:44:15.372759Z","shell.execute_reply.started":"2022-12-14T15:44:15.367033Z","shell.execute_reply":"2022-12-14T15:44:15.371225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n\ntransformer = RobustScaler()\ntransformer.fit(x_train_val_flattened)\nmedians=transformer.center_\nIQR=transformer.scale_\nprint(\"medians values : \",medians)\nprint(\"IQR ranges : \", IQR)\n\n\nx_train_val_scaled = x_train_val.copy()\n\nfor i in range(n_total):\n    x_train_val_scaled[i]=transformer.transform(x_train_val_scaled[i])\n\nprint()\nprint(\"Verification on a sample: \")\nprint(\" original : \" ,x_train_val[0][0])\nprint(\" robust scaled : \" ,x_train_val_scaled[0][0])\nshould_be = []\nfor f in range(6):\n    s=(x_train_val[0][0][f] - medians[f])/IQR[f]\n    should_be.append(s.round(7))\nprint(\" should be : \" ,should_be)\nprint()\n\nprint(\"Robust Scaling works well after verification.\")","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:58:44.564042Z","iopub.execute_input":"2022-12-15T09:58:44.564445Z","iopub.status.idle":"2022-12-15T09:58:44.745431Z","shell.execute_reply.started":"2022-12-15T09:58:44.564405Z","shell.execute_reply":"2022-12-15T09:58:44.744222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verification of the scaling impact on some examples\n\nrandom_index=np.random.randint(0,2428) \n\nprint(\"ORIGINAL :\")\nplot_example(random_index,x_train_val,y_train_val)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T15:51:20.536467Z","iopub.execute_input":"2022-12-14T15:51:20.536818Z","iopub.status.idle":"2022-12-14T15:51:21.292879Z","shell.execute_reply.started":"2022-12-14T15:51:20.536789Z","shell.execute_reply":"2022-12-14T15:51:21.291948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"NORMALIZED :\")\nplot_example(random_index,x_train_val_scaled,y_train_val)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T15:51:23.902737Z","iopub.execute_input":"2022-12-14T15:51:23.903085Z","iopub.status.idle":"2022-12-14T15:51:24.637723Z","shell.execute_reply.started":"2022-12-14T15:51:23.903054Z","shell.execute_reply":"2022-12-14T15:51:24.634080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SPLITTING\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x_train_val,y_train_val, test_size = 0.1, random_state=seed,stratify= y_train_val )","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:58:55.492469Z","iopub.execute_input":"2022-12-15T09:58:55.493137Z","iopub.status.idle":"2022-12-15T09:58:55.521341Z","shell.execute_reply.started":"2022-12-15T09:58:55.493100Z","shell.execute_reply":"2022-12-15T09:58:55.520345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape, x_val.shape)\nprint(y_train.shape, y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:58:57.331409Z","iopub.execute_input":"2022-12-15T09:58:57.331783Z","iopub.status.idle":"2022-12-15T09:58:57.338055Z","shell.execute_reply.started":"2022-12-15T09:58:57.331752Z","shell.execute_reply":"2022-12-15T09:58:57.336750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking repartitions after split, to see if it conserves repartition ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_class_repartitions={\"Wish\":0,\n\"Another\":0,\n\"Comfortably\":0,\n\"Money\":0,\n\"Breathe\":0,\n\"Time\":0,\n\"Brain\":0,\n\"Echoes\":0,\n\"Wearing\":0,\n\"Sorrow\":0,\n\"Hey\":0,\n\"Shine\":0}\n\nfor y in y_train:\n    label=labels[y]\n    train_class_repartitions[label]=train_class_repartitions[label]+1\n    \nS=0\nfor key in train_class_repartitions:\n    S=S+train_class_repartitions[key]\n\nprint( \"TRAINING SPLIT REPARTITION\")\nprint(\"TOTAL : \",S)\nplt.figure(figsize=(20,20))\nplt.bar(train_class_repartitions.keys(), train_class_repartitions.values(), color='g')","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:58:59.464710Z","iopub.execute_input":"2022-12-15T09:58:59.465069Z","iopub.status.idle":"2022-12-15T09:58:59.806503Z","shell.execute_reply.started":"2022-12-15T09:58:59.465037Z","shell.execute_reply":"2022-12-15T09:58:59.805310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_class_repartitions={\"Wish\":0,\n\"Another\":0,\n\"Comfortably\":0,\n\"Money\":0,\n\"Breathe\":0,\n\"Time\":0,\n\"Brain\":0,\n\"Echoes\":0,\n\"Wearing\":0,\n\"Sorrow\":0,\n\"Hey\":0,\n\"Shine\":0}\n\nfor y in y_val:\n    label=labels[y]\n    val_class_repartitions[label]=val_class_repartitions[label]+1\n    \nS=0\nfor key in val_class_repartitions:\n    S=S+val_class_repartitions[key]\n\nprint( \"VALIDATION SPLIT REPARTITION\")\nprint(\"TOTAL : \",S)\nplt.figure(figsize=(20,20))\nplt.bar(val_class_repartitions.keys(), val_class_repartitions.values(), color='g')","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:59:02.376993Z","iopub.execute_input":"2022-12-15T09:59:02.377429Z","iopub.status.idle":"2022-12-15T09:59:02.716024Z","shell.execute_reply.started":"2022-12-15T09:59:02.377376Z","shell.execute_reply":"2022-12-15T09:59:02.715079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding target variable\n\ny_train_categorical = tfk.utils.to_categorical(y_train)\ny_val_categorical =  tfk.utils.to_categorical(y_val)\n\nprint(y_train_categorical.shape,y_val_categorical.shape )","metadata":{"execution":{"iopub.status.busy":"2022-12-15T09:59:09.911583Z","iopub.execute_input":"2022-12-15T09:59:09.911981Z","iopub.status.idle":"2022-12-15T09:59:09.919148Z","shell.execute_reply.started":"2022-12-15T09:59:09.911949Z","shell.execute_reply":"2022-12-15T09:59:09.917750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MODEL BUILDING","metadata":{"execution":{"iopub.status.busy":"2022-12-11T15:32:50.231982Z","iopub.execute_input":"2022-12-11T15:32:50.232414Z","iopub.status.idle":"2022-12-11T15:32:50.237943Z","shell.execute_reply.started":"2022-12-11T15:32:50.232376Z","shell.execute_reply":"2022-12-11T15:32:50.236793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = x_train.shape[1:]\nclasses = y_train_categorical.shape[-1]\nbatch_size = 64\nepochs = 200","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:04:38.169637Z","iopub.execute_input":"2022-12-15T10:04:38.169966Z","iopub.status.idle":"2022-12-15T10:04:38.175107Z","shell.execute_reply.started":"2022-12-15T10:04:38.169937Z","shell.execute_reply":"2022-12-15T10:04:38.173972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ResNet model definition \n\n\ndef ResBs_Conv(block_input, num_filters): \n   \n    # 0. Filter Block input and BatchNormalization\n    block_input = tfkl.Conv1D(num_filters, kernel_size=7, strides=2,  padding='same')(block_input) \n    block_input = tfkl.BatchNormalization()(block_input)\n\n    # 1. First Convolutional Layer\n    conv1 = tfkl.Conv1D(filters=num_filters, kernel_size=7, padding='same')(block_input)\n    norm1 = tfkl.BatchNormalization()(conv1)\n    relu1 = tfkl.Activation('relu')(norm1)  \n    dropout = tfkl.Dropout(0.2)(relu1)\n    \n    # 2. Second Convolutional Layer \n    conv2 = tfkl.Conv1D(num_filters, kernel_size=7, padding='same')(dropout) #per avere concordanza\n    norm2 = tfkl.BatchNormalization()(conv2)\n\n    # 3. Summing Layer (adding a residual connection)\n    sum = tfkl.Add()([block_input, norm2])\n    \n    # 4. Activation Layer\n    relu2 = tfkl.Activation('relu')(sum)\n    \n    return relu2 \n\ndef ResBs_Identity(block_input, num_filters): \n\n    # 1. First Convolutional Layer\n    conv1 = tfkl.Conv1D(filters=num_filters, kernel_size=7, padding= 'same')(block_input)\n    norm1 = tfkl.BatchNormalization()(conv1)\n    relu1 = tfkl.Activation('relu')(norm1)    \n    dropout = tfkl.Dropout(0.2)(relu1)\n    \n    # 2. Second Convolutional Layer \n    conv2 = tfkl.Conv1D(num_filters, kernel_size=7, padding= 'same')(dropout) #per avere concordanza\n    norm2 = tfkl.BatchNormalization()(conv2)\n\n    # 3. Summing Layer (adding a residual connection)\n    sum = tfkl.Add()([block_input, norm2])\n    \n    # 4. Activation Layer\n    relu2 = tfkl.Activation('relu')(sum)\n    \n    return relu2 \n\ndef resnet(N, ch, win_len, classes): \n    input = tfkl.Input(shape=(win_len, ch)) \n\n    ResNet = tfkl.Conv1D(filters=64,kernel_size=15, padding = 'same')(input) \n    ResNet = tfkl.BatchNormalization()(ResNet)\n    ResNet = tfkl.Activation('relu')(ResNet)\n    ResNet = tfkl.MaxPooling1D(pool_size=2, strides = 2)(ResNet)\n    \n    # B.5 ResBs (x8) blocks\n    # First two ResNet blocks are identity blocks \n    ResNet = ResBs_Identity(ResNet, 64)\n    ResNet = ResBs_Identity(ResNet, 64)\n\n    filters = 64\n    M = int((N - 2)/2)\n    for i in range(M): \n        filters = filters * 2\n        # define N-th ResBs block\n        ResNet = ResBs_Conv(ResNet, filters)\n        ResNet = ResBs_Identity(ResNet, filters)\n    \n    ResNet = tfkl.GlobalAveragePooling1D(name='gmp_layer')(ResNet)\n#     ResNet = tfkl.Flatten()(ResNet) \n\n#     ResNet = tfkl.Dropout(0.2, seed=seed)(ResNet)\n#     ResNet= tfkl.Dense(\n#     512, \n#     activation='relu',\n#     kernel_initializer = tfk.initializers.HeUniform(seed))(ResNet)\n    \n    \n    # Softmax activation function on the last layer\n#     ResNet = tfkl.Dropout(0.3, seed=seed)(ResNet)\n    ResNet = tfkl.Dense(classes, activation='softmax')(ResNet)\n\n    \n    # Finally the model is composed by connecting inputs to outputs: \n    model = tfk.Model(inputs=[input],outputs=ResNet)\n    \n    \n    model.compile(\n        \n    optimizer = tfk.optimizers.Adam(),\n    loss = tfk.losses.CategoricalCrossentropy(),\n#     metrics = ['accuracy', 'Precision', 'Recall' ]\n    metrics = ['accuracy']\n    )\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:12:40.525268Z","iopub.execute_input":"2022-12-15T10:12:40.525647Z","iopub.status.idle":"2022-12-15T10:12:40.542841Z","shell.execute_reply.started":"2022-12-15T10:12:40.525614Z","shell.execute_reply":"2022-12-15T10:12:40.541717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = resnet(N=8, ch=6, win_len=36, classes=12)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:22:47.521358Z","iopub.execute_input":"2022-12-15T10:22:47.521759Z","iopub.status.idle":"2022-12-15T10:22:48.011064Z","shell.execute_reply.started":"2022-12-15T10:22:47.521731Z","shell.execute_reply":"2022-12-15T10:22:48.010052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAINING PHASE","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    x = x_train,\n    y = y_train_categorical,\n    batch_size = batch_size,\n    epochs = epochs,\n    validation_data=(x_val, y_val_categorical),\n     callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=50, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=30, factor=0.5, min_lr=1e-5)\n    ],\n    class_weight=class_loss_weights,\n   \n).history","metadata":{"execution":{"iopub.status.busy":"2022-12-15T10:24:07.581234Z","iopub.execute_input":"2022-12-15T10:24:07.581890Z","iopub.status.idle":"2022-12-15T10:24:07.668397Z","shell.execute_reply.started":"2022-12-15T10:24:07.581791Z","shell.execute_reply":"2022-12-15T10:24:07.667176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\n#Confution Matrix and Classification Report\n# Y_pred = model_gap.predict_generator(valid_gen,  706// batch_size+1)\nY_pred = model.predict(x_val)\ny_pred = np.argmax(Y_pred, axis=1)\n\ncm=confusion_matrix(y_val, y_pred)\n\ndisp=ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot(cmap=plt.cm.Blues)\n\n# Compute the classification metrics\naccuracy = accuracy_score(np.argmax(y_val_categorical, axis=-1), np.argmax(Y_pred, axis=-1))\nprecision = precision_score(np.argmax(y_val_categorical, axis=-1), np.argmax(Y_pred, axis=-1), average='macro')\nrecall = recall_score(np.argmax(y_val_categorical, axis=-1), np.argmax(Y_pred, axis=-1), average='macro')\nf1 = f1_score(np.argmax(y_val_categorical, axis=-1), np.argmax(Y_pred, axis=-1), average='macro')\nprint('Accuracy:',accuracy.round(4))\nprint('Precision:',precision.round(4))\nprint('Recall:',recall.round(4))\nprint('F1:',f1.round(4))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-14T17:04:39.541831Z","iopub.execute_input":"2022-12-14T17:04:39.542592Z","iopub.status.idle":"2022-12-14T17:04:57.259788Z","shell.execute_reply.started":"2022-12-14T17:04:39.542531Z","shell.execute_reply":"2022-12-14T17:04:57.258298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nmodel.save('resnet50')\nshutil.make_archive(\"resnet50\", 'zip', './resnet50')","metadata":{"execution":{"iopub.status.busy":"2022-12-12T11:49:49.634967Z","iopub.execute_input":"2022-12-12T11:49:49.635582Z","iopub.status.idle":"2022-12-12T11:49:59.590268Z","shell.execute_reply.started":"2022-12-12T11:49:49.635522Z","shell.execute_reply":"2022-12-12T11:49:59.588922Z"},"trusted":true},"execution_count":null,"outputs":[]}]}